from pyspark.sql import SparkSession
from pyspark.ml import Pipeline, PipelineModel
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.classification import LogisticRegression

import socket
import pyspark

SPARK_NAMESPACE="default"
SA="spark-driver"
K8S_CACERT="/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
K8S_TOKEN="/var/run/secrets/kubernetes.io/serviceaccount/token"
DOCKER_IMAGE="hishailesh77/spark_3_0_1:latest"
SPARK_DRIVER_HOST=socket.getfqdn()
SPARK_DRIVER_PORT=20020


if __name__ == "__main__":

    spark = SparkSession.builder \
        .appName("Malware Analysis") \
        .master("k8s://https://kubernetes.default:443") \
        .config("spark.kubernetes.authenticate.driver.serviceAccountName",SA) \
        .config("spark.kubernetes.namespace",SPARK_NAMESPACE) \
        .config("spark.kubernetes.authenticate.subdmission.caCertFile",K8S_CACERT) \
        .config("spark.kubernetes.authenticate.submission.oauthTokenFile",K8S_TOKEN) \
        .config("spark.kubernetes.container.image", DOCKER_IMAGE) \
        .config("spark.kubernetes.container.image.pullPolicy","Always") \
        .config("spark.driver.port",SPARK_DRIVER_PORT) \
        .config("spark.driver.host",SPARK_DRIVER_HOST) \
        .config("spark.executor.instances", "12") \
        .config("spark.driver.memory","16g") \
        .config("spark.executor.memory","16g") \
        .config("spark.driver.cores","8") \
        .config("spark.executor.cores","4") \
        .config("spark.memory.offHeap.enabled","true") \
        .config("spark.memory.offHeap.size","8g") \
        .config("spark.hadoop.fs.s3a.access.key", "AKIAX3D75DYHLQPYD4IT") \
        .config("spark.hadoop.fs.s3a.secret.key", "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") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.multiobjectdelete.enable","false") \
        .config("spark.hadoop.fs.s3a.fast.upload","true") \
        .getOrCreate()

    sc= spark.sparkContext.getOrCreate()

    df=spark.read.format("parquet").option("inferSchema", "true").option("header", "false").load("s3a://ml-workflow-data/security/Malware_Dataset/Output/malware_tmp_parquet_2")


    lr = LogisticRegression(maxIter=100)

    (trainingData, testData) = df.randomSplit([0.7, 0.3])

    pipeline = Pipeline(stages=[lr])

    model = pipeline.fit(trainingData)

    predictions = model.transform(testData)

    #predictions.select("prediction", "label", "features").show(5)

    #Fit and Transform the data and calculate accuracy
    evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
    accuracy = evaluator.evaluate(predictions)
    error=(1.0 -accuracy)


    print(f"Accuracy = {accuracy} , Test Error =  {error}")

    #Save the Model

    model.write().overwrite().save("s3a://ml-workflow-data/security/Malware_Dataset/Output/Model_LR_MaxITR_101")