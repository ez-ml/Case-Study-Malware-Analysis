{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
       "import scala.collection.mutable\n",
       "import org.apache.spark.ml.feature._\n",
       "import ml.dmlc.xgboost4j.scala.spark.{XGBoostClassificationModel, XGBoostClassifier}\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "SPARK_NAMESPACE: String = default\n",
       "SA: String = spark-driver\n",
       "K8S_CACERT: String = /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n",
       "K8S_TOKEN: String = /var/run/secrets/kubernetes.io/serviceaccount/token\n",
       "DOCKER_IMAGE: String = hishailesh77/spark-xgboost:latest\n",
       "SPARK_DRIVER_HOST: String = jupyter-lab-host.jupyter-headless.default.svc.cluster.local\n",
       "SPARK_DRIVER_PORT: String = 20020\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
    "\n",
    "import scala.collection.mutable\n",
    "import org.apache.spark.ml.feature._\n",
    "import ml.dmlc.xgboost4j.scala.spark.{XGBoostClassificationModel, XGBoostClassifier}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "\n",
    "val SPARK_NAMESPACE=\"default\"\n",
    "val SA=\"spark-driver\"\n",
    "val K8S_CACERT=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n",
    "val K8S_TOKEN=\"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n",
    "val DOCKER_IMAGE=\"hishailesh77/spark-xgboost:latest\"\n",
    "val SPARK_DRIVER_HOST= \"jupyter-lab-host.jupyter-headless.default.svc.cluster.local\"\n",
    "val SPARK_DRIVER_PORT=\"20020\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@6e5243f1\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    ".builder()\n",
    ".appName(\"Spark-Spylon\")\n",
    ".master(\"k8s://https://kubernetes.default:443\")\n",
    ".config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",SA)\n",
    ".config(\"spark.kubernetes.namespace\",SPARK_NAMESPACE)\n",
    ".config(\"spark.kubernetes.authenticate.subdmission.caCertFile\",K8S_CACERT)\n",
    ".config(\"spark.kubernetes.authenticate.submission.oauthTokenFile\",K8S_TOKEN)\n",
    ".config(\"spark.kubernetes.container.image\", DOCKER_IMAGE)\n",
    ".config(\"spark.kubernetes.container.image.pullPolicy\",\"Always\")\n",
    ".config(\"spark.driver.port\",SPARK_DRIVER_PORT)\n",
    ".config(\"spark.driver.host\",SPARK_DRIVER_HOST)\n",
    ".config(\"spark.executor.instances\", \"10\")\n",
    ".config(\"spark.driver.memory\",\"16g\")\n",
    ".config(\"spark.executor.memory\",\"16g\")\n",
    ".config(\"spark.driver.cores\",\"8\")\n",
    ".config(\"spark.executor.cores\",\"4\")\n",
    ".config(\"spark.hadoop.fs.s3a.access.key\", \"AKIAX3D75DYHLQPYD4IT\")\n",
    ".config(\"spark.hadoop.fs.s3a.secret.key\", \"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\")\n",
    ".config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    ".config(\"spark.hadoop.fs.s3a.multiobjectdelete.enable\",\"false\")\n",
    ".config(\"spark.hadoop.fs.s3a.fast.upload\",\"true\")\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [file_name: string, File: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df=spark.read.format(\"parquet\").option(\"inferSchema\", \"true\").\n",
    "    option(\"header\", \"false\").\n",
    "    load(\"s3a://ml-workflow-data/security/Malware_Dataset/Output/malware_tmp_parquet_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_partition: Int = 20\n",
       "alpha: Double = 0.01\n",
       "num_round: Int = 10\n",
       "num_classes: Int = 10\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val num_partition= 20\n",
    "val alpha = 0.01\n",
    "val num_round=10\n",
    "val num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n",
       "xgbParam: scala.collection.immutable.Map[String,Any] = Map(alpha -> 0.01, min_child_weight -> 3, trainTestRatio -> 0.9, skip_drop -> 0.5, seed -> 12345, num_workers -> 4, subsample -> 0.8, rate_drop -> 0.1, use_external_memory -> false, objective -> multi:softprob, num_round -> 10, colsample_bytree -> 0.8, gamma -> 0)\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "val xgbParam = Map(\n",
    "      \"use_external_memory\" -> false,\n",
    "      \"min_child_weight\" -> 3,\n",
    "      \"num_round\" -> num_round,\n",
    "      \"objective\" -> \"multi:softprob\",\n",
    "      \"use_external_memory\" -> false,\n",
    "      \"alpha\" -> alpha,\n",
    "      \"gamma\" -> 0,\n",
    "      \"subsample\" -> 0.8,\n",
    "      \"num_workers\" -> 4,\n",
    "      \"colsample_bytree\" -> 0.8,\n",
    "      \"trainTestRatio\" -> 0.9,\n",
    "      \"rate_drop\" -> 0.1,\n",
    "      \"skip_drop\" -> 0.5,\n",
    "      \"seed\" -> 12345L\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgbClassifier: ml.dmlc.xgboost4j.scala.spark.XGBoostClassifier = xgbc_9f1907d9b7a6\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xgbClassifier = new XGBoostClassifier(xgbParam)\n",
    "      .setFeaturesCol(\"features\")\n",
    "      .setLabelCol(\"label\")\n",
    "      .setPredictionCol(\"prediction\")\n",
    "      .setNumClass(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splits: Array[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] = Array([file_name: string, File: string ... 3 more fields], [file_name: string, File: string ... 3 more fields])\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val splits = df.randomSplit(Array(0.7, 0.3), seed = 11L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [file_name: string, File: string ... 3 more fields]\n",
       "testData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [file_name: string, File: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingData=splits(0)\n",
    "val testData=splits(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=192.168.1.36, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "xgbClassificationModel: ml.dmlc.xgboost4j.scala.spark.XGBoostClassificationModel = xgbc_9f1907d9b7a6\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xgbClassificationModel = xgbClassifier.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions: org.apache.spark.sql.DataFrame = [file_name: string, File: string ... 6 more fields]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = xgbClassificationModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|           file_name|                File|label|              countv|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|18eZt9qWksQhoY3K60aE|s3a://ml-workflow...|    2|(20,[0,1,2,3,4,5,...|[885721.0,529119....|[-1.0241112709045...|[0.00531960837543...|       2.0|\n",
      "|194Iy5xv8QRz7XMTnmAk|s3a://ml-workflow...|    3|(20,[0,1,2,3,4,5,...|[1093.0,1003.0,23...|[-1.0241112709045...|[0.00769972568377...|       3.0|\n",
      "|19b2dlEtWXyeiqc67Bof|s3a://ml-workflow...|    3|(20,[0,1,3,4,5,6,...|[1077.0,447.0,0.0...|[-1.0241112709045...|[0.00843319669365...|       3.0|\n",
      "|19lTEvHhVDprkGxgXLcf|s3a://ml-workflow...|    3|(20,[0,1,2,3,4,5,...|[787565.0,682404....|[-1.0241112709045...|[0.04056983068585...|       3.0|\n",
      "|19xM5LfBYviATcUkEOPm|s3a://ml-workflow...|    3|(20,[0,1,3,4,5,6,...|[1062.0,577.0,0.0...|[-1.0241112709045...|[0.00739023461937...|       3.0|\n",
      "|19zYbuW3XONcEedv7xUl|s3a://ml-workflow...|    1|(20,[0,1,2,3,4,5,...|[2433.0,3388.0,54...|[-1.0241112709045...|[0.01029085274785...|       1.0|\n",
      "|1AXVt0D9mSU26fL4iFGc|s3a://ml-workflow...|    1|(20,[0,1,2,3,4,5,...|[6323.0,6434.0,67...|[-1.0241112709045...|[0.02064077556133...|       1.0|\n",
      "|1AfYJKywcXSiI6H80nqE|s3a://ml-workflow...|    2|(20,[0,1,2,3,4,5,...|[2446056.0,140772...|[-1.0241112709045...|[0.00463646044954...|       2.0|\n",
      "|1OayZHFbz3tPBE5XNkcS|s3a://ml-workflow...|    3|(20,[0,1,3,4,5,6,...|[1074.0,431.0,0.0...|[-1.0241112709045...|[0.00683879572898...|       3.0|\n",
      "|8JdntIrPBj61FRx39cfb|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[68026.0,61404.0,...|[-1.0241112709045...|[0.01056628767400...|       4.0|\n",
      "|8LFCXHZ2TMdNhc7aUAGf|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[289888.0,249399....|[-1.0241112709045...|[0.03850987926125...|       4.0|\n",
      "|8QqTlOsYx5oLychRPgX3|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2391.0,1210.0,52...|[-1.0241112709045...|[0.00671276403591...|       7.0|\n",
      "|8a3GEC7cPKtx0lI6qYvL|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[34398.0,28088.0,...|[-1.0241112709045...|[0.03550694510340...|       4.0|\n",
      "|8hPsWwjKD51Z7BtmLNx4|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[280244.0,242019....|[-1.0241112709045...|[0.00629699835553...|       4.0|\n",
      "|8iDWJ4yKzNSAQjnxwO70|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2388.0,1163.0,53...|[-1.0241112709045...|[0.00671844696626...|       7.0|\n",
      "|8kVfT5MmuErjvdPsZxIY|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2389.0,1144.0,50...|[-1.0241112709045...|[0.00671188253909...|       7.0|\n",
      "|8wy0Pnkc3eJBq1WNSUFG|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[280078.0,241489....|[-1.0241112709045...|[0.00754462694749...|       4.0|\n",
      "|9CVbzaWsLvcHjPqZu2Q3|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[81494.0,70525.0,...|[-1.0241112709045...|[0.00558375427499...|       4.0|\n",
      "|Aoa1lgwOyETuRGsIHCe3|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2371.0,1206.0,50...|[-1.0241112709045...|[0.00670662289485...|       7.0|\n",
      "|a7xm4JhCvO9NWVeKMEBn|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2390.0,1141.0,51...|[-1.0241112709045...|[0.00671844696626...|       7.0|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = MulticlassClassificationEvaluator: uid=mcEval_c576b06c53d2, metricName=accuracy, metricLabel=0.0, beta=1.0, eps=1.0E-15\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    "      .setLabelCol(\"label\")\n",
    "      .setPredictionCol(\"prediction\")\n",
    "      .setMetricName(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "Accuracy = 94.11764705882352 %\n",
      "#####################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "accuracy: Double = 0.9411764705882353\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val accuracy = evaluator.evaluate(predictions)\n",
    "    println(\"#####################################################################\")\n",
    "    println(\"Accuracy = \"+ (accuracy * 100) + \" %\")\n",
    "    println(\"#####################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
