{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip Dataset.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare the vectorizers\n",
    "count_vectorizer=CountVectorizer(stop_words='english',max_features=100)\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english',max_features=100)\n",
    "hashing_vectorizer=HashingVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list=[]\n",
    "text_list=[]\n",
    "file_list=[]\n",
    "fileDir=\"Section1-Chapter3\"\n",
    "df=pd.read_csv(fileDir+\"/Labels.csv\")\n",
    "\n",
    "for row in df.itertuples(index=True, name='Pandas'):\n",
    "    fileName=row.FileName+'.asm'\n",
    "    with open(\"Section1-Chapter3/\"+fileName, encoding='utf-8', errors='ignore') as f:\n",
    "        content=f.read()\n",
    "    content.replace(\",\", \" \")\n",
    "    content.replace('\"', \" \")\n",
    "    text_list.append(content)\n",
    "    file_list.append(fileName)\n",
    "    label_list.append(row.Label)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe for Count Vectorizer\n",
    "dtm=count_vectorizer.fit_transform(text_list)\n",
    "df_count=pd.DataFrame(dtm.toarray(),columns=count_vectorizer.get_feature_names())\n",
    "df_count['FileName']=pd.Series(file_list)\n",
    "df_count['Label']=pd.Series(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe for TF-IDF Vectorizer\n",
    "dtm=tfidf_vectorizer.fit_transform(text_list)\n",
    "df_tfidf=pd.DataFrame(dtm.toarray(),columns=tfidf_vectorizer.get_feature_names())\n",
    "df_tfidf['FileName']=pd.Series(file_list)\n",
    "df_tfidf['Label']=pd.Series(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engneering section\n",
    "df_count.to_csv('count_vectorizer.csv.zip', index=False,compression=\"zip\") \n",
    "df_tfidf.to_csv('tfidf_vectorizer.csv.zip', index=False,compression=\"zip\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count=pd.read_csv(\"count_vectorizer.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf=pd.read_csv(\"tfidf_vectorizer.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the Feature and Target lable matrix \n",
    "Label_CV=df_count['Label']\n",
    "Features_CV = df_count.drop( columns=['FileName', 'Label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_TF=df_tfidf['Label']\n",
    "Features_TF= df_tfidf.drop( columns=['FileName', 'Label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the input and splitting train test data \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_CF_Normalized=StandardScaler().fit_transform(Features_CV)\n",
    "X_TF_Normalized=StandardScaler().fit_transform(Features_TF)\n",
    "\n",
    "X_CF_Train, X_CF_Test, Y_CF_Train, Y_CF_Test= train_test_split(X_CF_Normalized,Label_CV,test_size=0.20, shuffle=True)\n",
    "\n",
    "X_TF_Train, X_TF_Test, Y_TF_Train, Y_TF_Test= train_test_split(X_TF_Normalized,Label_TF,test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg_cf=LogisticRegression()\n",
    "logReg_cf.fit(X_CF_Train,Y_CF_Train)\n",
    "\n",
    "\n",
    "logReg_tf=LogisticRegression()\n",
    "logReg_tf.fit(X_TF_Train,Y_TF_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the above model and get predictions \n",
    "predictions_cf=logReg_cf.predict(X_CF_Test)\n",
    "\n",
    "predictions_tf=logReg_tf.predict(X_TF_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Util Function\n",
    "from sklearn.metrics import accuracy_score\n",
    "from prettytable import PrettyTable\n",
    "def print_stats_metrices(algorithm_name, y_test, y_pred):\n",
    "    x = PrettyTable()\n",
    "    x.field_names = [\"Algorithm\", \"Accuracy\"]\n",
    "    \n",
    "    acc_score=accuracy_score(y_test, y_pred)\n",
    "    x.add_row([algorithm_name,acc_score]);\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats_metrices('LogisticRegression',Y_CF_Test,predictions_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats_metrices('LogisticRegression',Y_TF_Test,predictions_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}