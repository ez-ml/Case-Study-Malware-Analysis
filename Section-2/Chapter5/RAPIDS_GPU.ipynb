{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install nltk\n",
    "!python3 -m nltk.downloader stopwords\n",
    "!unzip Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "from cuml.experimental.preprocessing import StandardScaler\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from cuml.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list=[]\n",
    "text_list=[]\n",
    "file_list=[]\n",
    "fileDir=\"Section1-Chapter3\"\n",
    "\n",
    "\n",
    "df = cudf.read_csv(fileDir+\"/Labels.csv\")\n",
    "for row in df.to_pandas().itertuples(index=True, name='Pandas'):\n",
    "    fileName=row.FileName+'.asm'\n",
    "    with open(\"Section1-Chapter3/\"+fileName, encoding='utf-8', errors='ignore') as f:\n",
    "        content=f.read()\n",
    "    content.replace(\",\", \" \")\n",
    "    content.replace('\"', \" \")\n",
    "    text_list.append(content)\n",
    "    file_list.append(fileName)\n",
    "    label_list.append(row.Label)   \n",
    "\n",
    "df['Text']=cudf.Series(text_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer=CountVectorizer(stop_words='english',max_features=100)\n",
    "features = count_vectorizer.fit_transform(df['Text'].to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = cudf.DataFrame(features.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "df_count['FileName']=cudf.Series(file_list)\n",
    "df_count['Label']=cudf.Series(label_list)\n",
    "\n",
    "Label_CV=df_count['Label']\n",
    "Features_CV = df_count.drop( columns=['FileName', 'Label'], axis=1)\n",
    "\n",
    "X_CF_Normalized=StandardScaler().fit_transform(Features_CV)\n",
    "X_CF_Train, X_CF_Test, Y_CF_Train, Y_CF_Test= train_test_split(X_CF_Normalized,Label_CV,test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.linear_model import LogisticRegression\n",
    "\n",
    "logReg_cf=LogisticRegression()\n",
    "logReg_cf.fit(X_CF_Train,Y_CF_Train)\n",
    "logReg_cf.score(X_CF_Train,Y_CF_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "knn.fit(X_CF_Train,Y_CF_Train)\n",
    "knn.score(X_CF_Train,Y_CF_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}