Feature Engineering using Spark Dataframe in Scala .

Show default partitions and explain Right balance of repartitioning .


Show S3 Parquet Output

Explain that why we have two feature engineering file, and show the difference in executor and core resources requested .


Package the application using sbt , docker and submit it .


export SPARK_NAMESPACE=default \
export SA=spark-driver \
export K8S_CACERT=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt \
export K8S_TOKEN=/var/run/secrets/kubernetes.io/serviceaccount/token \
export DOCKER_IMAGE=hishailesh77/feature1:v1 \
export SPARK_DRIVER_HOST=malware-feature-host.malware-feature-headless.default.svc.cluster.local \
export SPARK_DRIVER_PORT=20020 \

/opt/spark/bin/spark-submit --name sparkpi-test1 \
--master k8s://https://kubernetes.default:443 \
--deploy-mode client  \
--class FeatureEngineering1  \
--conf spark.kubernetes.authenticate.subdmission.caCertFile=$K8S_CACERT  \
--conf spark.kubernetes.authenticate.submission.oauthTokenFile=$K8S_TOKEN  \
--conf spark.kubernetes.authenticate.driver.serviceAccountName=$SA  \
--conf spark.kubernetes.namespace=$SPARK_NAMESPACE  \
--conf spark.executor.instances=12  \
--conf spark.driver.memory=16g  \
--conf spark.executor.memory=8g  \
--conf spark.driver.cores=8  \
--conf spark.executor.cores=4  \
--conf spark.memory.offHeap.enabled=true  \
--conf spark.memory.offHeap.size=8g  \
--conf spark.hadoop.fs.s3a.access.key=AKIAX3D75DYHLQPYD4IT  \
--conf spark.hadoop.fs.s3a.secret.key=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  \
--conf spark.kubernetes.container.image=$DOCKER_IMAGE  \
--conf spark.kubernetes.container.image.pullPolicy=Always \
--conf spark.driver.host=$SPARK_DRIVER_HOST \
--conf spark.driver.port=$SPARK_DRIVER_PORT \
local:///opt/spark/work-dir/malwarefeatureengineering_2.11-1.0.jar




Docker build -t hishailesh77/feature1:v1 -f FeatureEngineering.Dockerfile .
Docker push hishailesh77/feature1:v1
kubectl apply -f Feature1-deployment.yaml


sbt package
Docker build -t hishailesh77/spark_3_0_1:latest -f Base3_0_1.Dockerfile . && docker push hishailesh77/spark_3_0_1:latest \
&& Docker build -t hishailesh77/feature:v1 -f FeatureEngineering.Dockerfile . &&  Docker push hishailesh77/feature:v1 \
&& kubectl delete job malware-feature && kubectl apply -f Feature-Job.yaml


helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add stable https://kubernetes-charts.storage.googleapis.com/
helm repo update


helm install prometheus stable/prometheus-operator

helm install prometheus-operator prometheus-community/kube-prometheus-stack




kubectl apply -f Spark-Job-Deployment.yaml
Kubectl delete job spark-job && kubectl delete service spark-app-lb &&  kubectl delete service spark-svc-headless && kubectl delete service spark-app-lb
Kubectl delete job malware-feature && kubectl delete service malware-feature &&  kubectl delete service malware-feature-headless && kubectl delete service malware-feature-lb

