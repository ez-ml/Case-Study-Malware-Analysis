{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
       "import org.apache.spark._\n",
       "import org.apache.spark.rdd.RDD\n",
       "import spark.implicits._\n",
       "SPARK_NAMESPACE: String = default\n",
       "SA: String = spark-driver\n",
       "K8S_CACERT: String = /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n",
       "K8S_TOKEN: String = /var/run/secrets/kubernetes.io/serviceaccount/token\n",
       "DOCKER_IMAGE: String = hishailesh77/spark2.4.6-deb:latest\n",
       "SPARK_DRIVER_HOST: String = jupyter-lab-host.jupyter-headless.default.svc.cluster.local\n",
       "SPARK_DRIVER_PORT: String = 20020\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import spark.implicits._\n",
    "\n",
    "\n",
    "val SPARK_NAMESPACE=\"default\"\n",
    "val SA=\"spark-driver\"\n",
    "val K8S_CACERT=\"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n",
    "val K8S_TOKEN=\"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n",
    "val DOCKER_IMAGE=\"hishailesh77/spark_3_0_1:latest\"\n",
    "val SPARK_DRIVER_HOST= \"jupyter-lab-host.jupyter-headless.default.svc.cluster.local\"\n",
    "val SPARK_DRIVER_PORT=\"20020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@511947b2\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    ".builder()\n",
    ".appName(\"Spark-Spylon\")\n",
    ".master(\"k8s://https://kubernetes.default:443\")\n",
    ".config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",SA)\n",
    ".config(\"spark.kubernetes.namespace\",SPARK_NAMESPACE)\n",
    ".config(\"spark.kubernetes.authenticate.subdmission.caCertFile\",K8S_CACERT)\n",
    ".config(\"spark.kubernetes.authenticate.submission.oauthTokenFile\",K8S_TOKEN)\n",
    ".config(\"spark.kubernetes.container.image\", DOCKER_IMAGE)\n",
    ".config(\"spark.kubernetes.container.image.pullPolicy\",\"Always\")\n",
    ".config(\"spark.driver.port\",SPARK_DRIVER_PORT)\n",
    ".config(\"spark.driver.host\",SPARK_DRIVER_HOST)\n",
    ".config(\"spark.executor.instances\", \"12\")\n",
    ".config(\"spark.driver.memory\",\"16g\")\n",
    ".config(\"spark.executor.memory\",\"16g\")\n",
    ".config(\"spark.driver.cores\",\"8\")\n",
    ".config(\"spark.executor.cores\",\"4\")\n",
    ".config(\"spark.memory.offHeap.enabled\",\"true\")\n",
    ".config(\"spark.memory.offHeap.size\",\"8g\")\n",
    ".config(\"spark.hadoop.fs.s3a.access.key\", \"\")\n",
    ".config(\"spark.hadoop.fs.s3a.secret.key\", \"\")\n",
    ".config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    ".config(\"spark.hadoop.fs.s3a.multiobjectdelete.enable\",\"false\")\n",
    ".config(\"spark.hadoop.fs.s3a.fast.upload\",\"true\")\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n",
       "import spark.sql\n",
       "df_1: org.apache.spark.sql.DataFrame = [file_name: string, File: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "import spark.sql\n",
    "\n",
    "val df_1 = spark.read.format(\"parquet\").option(\"inferSchema\", \"true\").\n",
    "    option(\"header\", \"false\").\n",
    "    load(\"s3a://ml-workflow-data/security/Malware_Dataset/Output/malware_tmp_parquet_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Int = 51\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [file_name: string, File: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_2 = df_1.repartition(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.Pipeline\n",
       "import org.apache.spark.ml.feature.{CountVectorizer, RegexTokenizer, StopWordsRemover, VectorAssembler}\n",
       "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
       "featureEngineeringCountV: (dataMatrix: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.feature.{CountVectorizer, RegexTokenizer, StopWordsRemover, VectorAssembler}\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "def featureEngineeringCountV(dataMatrix: DataFrame): DataFrame ={\n",
    "\n",
    "      val tokenizer = new RegexTokenizer().setInputCol(\"Text\").setOutputCol(\"wordsArray\")\n",
    "      val remover = new StopWordsRemover().setInputCol(\"wordsArray\").setOutputCol(\"filteredWords\")\n",
    "      val cnt = new  CountVectorizer().setInputCol(\"filteredWords\").setOutputCol(\"countv\").setVocabSize(20)\n",
    "      val assembler = new VectorAssembler().setInputCols(Array(\"countv\")).setOutputCol(\"features\")\n",
    "      val pipeline = new Pipeline().setStages(Array(tokenizer, remover, cnt, assembler))\n",
    "      val model= pipeline.fit(dataMatrix)\n",
    "      model.transform(dataMatrix).drop(\"Text\",\"wordsArray\",\"filteredWords\")\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_df: org.apache.spark.sql.DataFrame = [file_name: string, File: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val final_df = featureEngineeringCountV(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.coalesce(100).write.mode(\"overwrite\").format(\"parquet\").option(\"compression\", \"snappy\").mode(\"overwrite\").save(\"s3a://ml-workflow-data/security/Malware_Dataset/Output/malware_tmp_parquet_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_df: org.apache.spark.sql.DataFrame = [file_name: string, File: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val test_df=spark.read.format(\"parquet\").option(\"inferSchema\", \"true\").\n",
    "    option(\"header\", \"false\").\n",
    "    load(\"s3a://ml-workflow-data/security/Malware_Dataset/Output/malware_tmp_parquet_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|           file_name|                File|label|              countv|            features|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|13YpdP5vTLOazSQFRgJn|s3a://ml-workflow...|    3|(20,[0,1,3,4,5,6,...|[1094.0,564.0,0.0...|\n",
      "|12tjh4qCkcHpObVBEeMr|s3a://ml-workflow...|    3|(20,[0,1,2,3,4,5,...|[2843.0,2300.0,86...|\n",
      "|15loeAHtkJa8BuFi6Zry|s3a://ml-workflow...|    1|(20,[0,1,2,3,4,5,...|[126025.0,107847....|\n",
      "|4JGbOVQnEt3ZP5acW7Yz|s3a://ml-workflow...|    6|(20,[0,1,2,3,4,5,...|[146066.0,130765....|\n",
      "|5YMeDkHjclrCPd8OuymR|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[76734.0,68712.0,...|\n",
      "|12Jd4qpOzTtQC3E6PXDb|s3a://ml-workflow...|    3|(20,[0,1,3,4,5,6,...|[1095.0,561.0,0.0...|\n",
      "|7KqfVlEBOmr6tTQewNG8|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2387.0,1167.0,48...|\n",
      "|5PBvwNE8sCzm1bjUlf6A|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2384.0,1169.0,49...|\n",
      "|6cylqphx5sHCm4fYBEdK|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2386.0,1174.0,52...|\n",
      "|7J4un8UNCgcPYmzsyxZI|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[94992.0,81582.0,...|\n",
      "|129LWuNOIS0RjQnq5om6|s3a://ml-workflow...|    3|(20,[0,1,3,4,5,6,...|[1066.0,428.0,0.0...|\n",
      "|7Ebd8M0gDHBRIjFvr6SQ|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[97684.0,84637.0,...|\n",
      "|7KHscjvztoka0QpqYFxb|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[39494.0,34922.0,...|\n",
      "|5JfdLYbqX8oFmD1WTg97|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[76719.0,68146.0,...|\n",
      "|6d0uJ9rYK1FcjRimvVNt|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[104409.0,86829.0...|\n",
      "|5QjzywcSG4XLhNRt8unq|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2370.0,1185.0,51...|\n",
      "|5QOWxyz7oqf9T6KIBDbk|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[87480.0,75488.0,...|\n",
      "|3AJgNPo6iqT8BeODfxHK|s3a://ml-workflow...|    8|(20,[0,1,2,3,4,5,...|[16926.0,4007.0,2...|\n",
      "|5JLHiDhkzyYPdTeuMqXb|s3a://ml-workflow...|    4|(20,[0,1,2,3,4,5,...|[76241.0,68343.0,...|\n",
      "|6WrBNPTRljxmLahZzo5s|s3a://ml-workflow...|    7|(20,[0,1,2,3,4,5,...|[2383.0,1157.0,50...|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}